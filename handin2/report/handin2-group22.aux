\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*{\memsetcounter}[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}SVM with SciKit-Learn}{1}{chapter.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Polynomial kernels}{1}{section.1.1}}
\@writefile{lox}{\contentsline {fixme}{Fatal: should we measure or mention training time? (mention multithreaded solution?)}{1}{section.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces SVM performance with a simple linear(1st order polynomial) kernel for various $C$ values(cost).}}{1}{figure.1.1}}
\newlabel{fig:svm_lin}{{\M@TitleReference {1}{SVM performance with a simple linear(1st order polynomial) kernel for various $C$ values(cost).}}{1}{SVM performance with a simple linear(1st order polynomial) kernel for various $C$ values(cost)}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces SVM performance with a second-order polynomial kernel for various $C$ values(cost).}}{2}{figure.1.2}}
\newlabel{fig:svm_poly2}{{\M@TitleReference {2}{SVM performance with a second-order polynomial kernel for various $C$ values(cost).}}{2}{SVM performance with a second-order polynomial kernel for various $C$ values(cost)}{figure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces SVM performance with a third-order polynomial kernel for various $C$ values(cost).}}{2}{figure.1.3}}
\newlabel{fig:svm_poly3}{{\M@TitleReference {3}{SVM performance with a third-order polynomial kernel for various $C$ values(cost).}}{2}{SVM performance with a third-order polynomial kernel for various $C$ values(cost)}{figure.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}RBF kernel}{2}{section.1.2}}
\@writefile{lox}{\contentsline {fixme}{Fatal: Explain this better...}{2}{section.1.2}}
\@writefile{lox}{\contentsline {fixme}{Fatal: Comment on overfitting and the different 'areas' on the 3D plot, Morten}{2}{section.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces SVM classification accuracy with a RBF kernel with $\gamma =0.01$ for various $C$ values(cost).}}{3}{figure.1.4}}
\newlabel{fig:svm_rbf}{{\M@TitleReference {4}{SVM classification accuracy with a RBF kernel with $\gamma =0.01$ for various $C$ values(cost).}}{3}{SVM classification accuracy with a RBF kernel with $\gamma =0.01$ for various $C$ values(cost)}{figure.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces SVM classification accuracy with a RBF kernel with various $\gamma $- and $C$ values(cost).}}{3}{figure.1.5}}
\newlabel{fig:svm_rbf_grid}{{\M@TitleReference {5}{SVM classification accuracy with a RBF kernel with various $\gamma $- and $C$ values(cost).}}{3}{SVM classification accuracy with a RBF kernel with various $\gamma $- and $C$ values(cost)}{figure.1.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Classification accuracy of digits with different kernels for the found optimal hyperparameters. }}{4}{table.1.1}}
\newlabel{tab:svm_accuracy}{{\M@TitleReference {1}{Classification accuracy of digits with different kernels for the found optimal hyperparameters. }}{4}{Classification accuracy of digits with different kernels for the found optimal hyperparameters. }{table.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Illustration of a small NN, with one hidden layer. In our case the input vector consists of the $784$ pixel values for an image, the hidden layer has $1024$ nodes, and the output layer has $10$ nodes, one for each digit-class. Biases are added for both computational layers.}}{4}{figure.2.6}}
\newlabel{fig:nn_layout}{{\M@TitleReference {6}{Illustration of a small NN, with one hidden layer. In our case the input vector consists of the $784$ pixel values for an image, the hidden layer has $1024$ nodes, and the output layer has $10$ nodes, one for each digit-class. Biases are added for both computational layers.}}{4}{Illustration of a small NN, with one hidden layer. In our case the input vector consists of the $784$ pixel values for an image, the hidden layer has $1024$ nodes, and the output layer has $10$ nodes, one for each digit-class. Biases are added for both computational layers}{figure.2.6}{}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Neural Nets with TensorFlow}{4}{chapter.2}}
\@writefile{lox}{\contentsline {fixme}{Fatal: Hyperparameters: learning rate, batchsize, epochs to run, }{4}{figure.2.6}}
\@writefile{lox}{\contentsline {fixme}{Fatal: training time}{4}{figure.2.6}}
\@writefile{lox}{\contentsline {fixme}{Fatal: results}{4}{figure.2.6}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Making the best classifier in 2016 ML Class}{4}{chapter.3}}
\@writefile{lox}{\contentsline {fixme}{Fatal: describe combination of datasets to achieve larger training set}{4}{chapter.3}}
\@writefile{lox}{\contentsline {fixme}{Fatal: Hyperparameters: learning rate, batchsize, epochs to run, }{4}{chapter.3}}
\@writefile{lox}{\contentsline {fixme}{Fatal: illustrate convolutional network}{4}{chapter.3}}
\@writefile{lox}{\contentsline {fixme}{Fatal: results}{4}{chapter.3}}
\memsetcounter{lastsheet}{4}
\memsetcounter{lastpage}{4}
