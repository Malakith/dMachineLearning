\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*{\memsetcounter}[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}SVM with SciKit-Learn}{1}{chapter.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Polynomial kernels}{1}{section.1.1}}
\@writefile{lox}{\contentsline {fixme}{Fatal: should we measure or mention training time? (mention multithreaded solution?)}{1}{section.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \emph  {SVM performance with a simple linear(1st order polynomial) kernel for various $C$ values(cost).}}}{1}{figure.1.1}}
\newlabel{fig:svm_lin}{{\M@TitleReference {1}{\emph  {SVM performance with a simple linear(1st order polynomial) kernel for various $C$ values(cost).}}}{1}{\emph {SVM performance with a simple linear(1st order polynomial) kernel for various $C$ values(cost).}}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \emph  {SVM performance with a second-order polynomial kernel for various $C$ values(cost).}}}{2}{figure.1.2}}
\newlabel{fig:svm_poly2}{{\M@TitleReference {2}{\emph  {SVM performance with a second-order polynomial kernel for various $C$ values(cost).}}}{2}{\emph {SVM performance with a second-order polynomial kernel for various $C$ values(cost).}}{figure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \emph  {SVM performance with a third-order polynomial kernel for various $C$ values(cost).}}}{2}{figure.1.3}}
\newlabel{fig:svm_poly3}{{\M@TitleReference {3}{\emph  {SVM performance with a third-order polynomial kernel for various $C$ values(cost).}}}{2}{\emph {SVM performance with a third-order polynomial kernel for various $C$ values(cost).}}{figure.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}RBF kernel}{2}{section.1.2}}
\@writefile{lox}{\contentsline {fixme}{Fatal: Explain this better...}{2}{section.1.2}}
\@writefile{lox}{\contentsline {fixme}{Fatal: Comment on overfitting and the different 'areas' on the 3D plot, Morten}{2}{section.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \emph  {SVM classification accuracy with a RBF kernel with $\gamma =0.01$ for various $C$ values(cost).}}}{3}{figure.1.4}}
\newlabel{fig:svm_rbf}{{\M@TitleReference {4}{\emph  {SVM classification accuracy with a RBF kernel with $\gamma =0.01$ for various $C$ values(cost).}}}{3}{\emph {SVM classification accuracy with a RBF kernel with $\gamma =0.01$ for various $C$ values(cost).}}{figure.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \emph  {SVM classification accuracy with a RBF kernel with various $\gamma $- and $C$ values(cost).}}}{3}{figure.1.5}}
\newlabel{fig:svm_rbf_grid}{{\M@TitleReference {5}{\emph  {SVM classification accuracy with a RBF kernel with various $\gamma $- and $C$ values(cost).}}}{3}{\emph {SVM classification accuracy with a RBF kernel with various $\gamma $- and $C$ values(cost).}}{figure.1.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \emph  {Classification accuracy with different kernels for the found optimal hyperparameters. }}}{4}{table.1.1}}
\newlabel{tab:svm_accuracy}{{\M@TitleReference {1}{\emph  {Classification accuracy with different kernels for the found optimal hyperparameters. }}}{4}{\emph {Classification accuracy with different kernels for the found optimal hyperparameters. }}{table.1.1}{}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Neural Nets with TensorFlow}{4}{chapter.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \emph  {Illustration of a small NN, with one hidden layer. In our case the input vector consists of the $784$ pixel values for an image, the hidden layer has $1024$ nodes, and the output layer has $10$ nodes, one for each digit-class. Biases are added for both computational layers.}}}{4}{figure.2.6}}
\newlabel{fig:nn_layout}{{\M@TitleReference {6}{\emph  {Illustration of a small NN, with one hidden layer. In our case the input vector consists of the $784$ pixel values for an image, the hidden layer has $1024$ nodes, and the output layer has $10$ nodes, one for each digit-class. Biases are added for both computational layers.}}}{4}{\emph {Illustration of a small NN, with one hidden layer. In our case the input vector consists of the $784$ pixel values for an image, the hidden layer has $1024$ nodes, and the output layer has $10$ nodes, one for each digit-class. Biases are added for both computational layers.}}{figure.2.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Improved (combined) training set}{4}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Training}{5}{section.2.2}}
\@writefile{lox}{\contentsline {fixme}{Fatal: explain param init}{5}{section.2.2}}
\@writefile{lox}{\contentsline {fixme}{Fatal: training time?}{5}{section.2.2}}
\@writefile{lox}{\contentsline {fixme}{Fatal: results}{5}{section.2.2}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Making the best classifier in 2016 ML Class}{5}{chapter.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \emph  {Illustration of the CNN. Two $5 x 5$ convolution layers and $2 x 2$ max pooling layers before a fully connected layer of $1024 nodes$ and the fully connected output layer of $10$ nodes. Input monochrome images of $28x28$ pixels assumed.}}}{5}{figure.3.7}}
\newlabel{fig:cnn_layout}{{\M@TitleReference {7}{\emph  {Illustration of the CNN. Two $5 x 5$ convolution layers and $2 x 2$ max pooling layers before a fully connected layer of $1024 nodes$ and the fully connected output layer of $10$ nodes. Input monochrome images of $28x28$ pixels assumed.}}}{5}{\emph {Illustration of the CNN. Two $5 x 5$ convolution layers and $2 x 2$ max pooling layers before a fully connected layer of $1024 nodes$ and the fully connected output layer of $10$ nodes. Input monochrome images of $28x28$ pixels assumed.}}{figure.3.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Training}{5}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Hyperparameters}{5}{section.3.2}}
\@writefile{lox}{\contentsline {fixme}{Fatal: Hyperparameters: learning rate, batchsize, epochs to run, }{5}{section.3.2}}
\@writefile{lox}{\contentsline {fixme}{Fatal: results}{5}{section.3.2}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \emph  {Classification accuracy for the RBF kernel SVM, simple neural network with one hidden layer, and convolution neural network, all trained on the combined AUtrain and MNIST set, and validated with AUtest. }}}{6}{table.3.2}}
\newlabel{tab:classifier_accuracy}{{\M@TitleReference {2}{\emph  {Classification accuracy for the RBF kernel SVM, simple neural network with one hidden layer, and convolution neural network, all trained on the combined AUtrain and MNIST set, and validated with AUtest. }}}{6}{\emph {Classification accuracy for the RBF kernel SVM, simple neural network with one hidden layer, and convolution neural network, all trained on the combined AUtrain and MNIST set, and validated with AUtest. }}{table.3.2}{}}
\memsetcounter{lastsheet}{6}
\memsetcounter{lastpage}{6}
