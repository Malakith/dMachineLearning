{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000]\n",
      "[1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# oh so pretty!\n",
    "def float_formatter(x):\n",
    "    if x < 0.001 and x > 0:\n",
    "        return \"   >0\" \n",
    "    elif x == 0:\n",
    "        return \"    0\" \n",
    "    else:\n",
    "        return \"%.3f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "A = np.random.rand(500,500)\n",
    "A = A/A.sum(axis=1)[:,None]\n",
    "print(A.sum(axis=1))\n",
    "\n",
    "E = np.random.rand(500, 4)\n",
    "E = E / E.sum(axis=1)[:,None]\n",
    "print(E.sum(axis=1))\n",
    "pi = np.random.rand(500)\n",
    "pi = pi/pi.sum()\n",
    "print(pi.sum())\n",
    "\n",
    "def write_fasta_file(annotation_file_to_save, annotation_string, genome_file=None):\n",
    "    if (genome_file!=None):\n",
    "        with open(genome_file) as gf:\n",
    "            first_line = gf.readline()\n",
    "            s = \" \"\n",
    "            words = first_line.split(s)\n",
    "            words[0] = words[0] + \" gene annotation\"\n",
    "            first_line = s.join(words[:-1])\n",
    "    else:\n",
    "        first_line = \"; gene annotation\"\n",
    "    with open(annotation_file_to_save, 'w+') as af:\n",
    "        af.write(first_line + '\\n')\n",
    "        name = annotation_file_to_save.replace('/', '\\\\').split('\\\\')[-1].split('.fa')[0]\n",
    "        af.write('>' + name + '\\n')\n",
    "        line_length = 60\n",
    "        full_lines = len(annotation_string)//line_length\n",
    "        for anot_line in range(full_lines):\n",
    "            af.write(annotation_string[anot_line*line_length:(anot_line+1)*line_length] + '\\n')\n",
    "        af.write(annotation_string[(full_lines)*line_length:])\n",
    "       \n",
    "    \n",
    "# eg\n",
    "#write_fasta_file(\"data/annotation13.fa\", \"ABABABABABABABABABAAAAJHASJHASJJSdskfjklsfkjklj sdhjkøfhjkø ksdhjf jkjkhsdfjk hjksdf hjksdfjk jhksd fhjkdsfhjk AJJSJHASHJASJJHASJHASJHASJHSAJJHASJHASHJASJJHASJHASJJHASJH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GG': 13, 'CA': 6, 'TT': 19, 'AC': 2, 'CG': 8, 'AT': 4, 'AG': 3, 'GC': 12, 'GA': 11, 'CT': 9, 'GT': 14, 'A': 0, 'T': 15, 'TA': 16, 'AA': 1, 'TG': 18, 'G': 10, 'TC': 17, 'C': 5, 'CC': 7}\n",
      "['A' 'AA' 'AC' 'AG' 'AT' 'C' 'CA' 'CC' 'CG' 'CT' 'G' 'GA' 'GC' 'GG' 'GT'\n",
      " 'T' 'TA' 'TC' 'TG' 'TT']\n"
     ]
    }
   ],
   "source": [
    "# define all possible outcomes of all states:\n",
    "outcomes_dict = {} # ohh gawd this is akward\n",
    "outcomes = np.empty([20], dtype=object) # help me, im lost\n",
    "i = 0\n",
    "letters = 'ACGT'\n",
    "for letter1 in letters:\n",
    "    outcomes[i] = letter1\n",
    "    outcomes_dict[letter1] = i\n",
    "    i += 1\n",
    "    for letter2 in letters:\n",
    "        outcomes[i] = letter1 + letter2# + letter3\n",
    "        #outcomes_dict[letter1 + letter2 + letter3] = i\n",
    "        outcomes_dict[letter1 + letter2] = i\n",
    "        i += 1\n",
    "\n",
    "print(outcomes_dict)\n",
    "print(outcomes)\n",
    "#outcomes_dict = alphabet\n",
    "#outcomes=np.asarray(('A', 'C', 'G', 'T'))\n",
    "#ACGT\n",
    "def l2i(l):\n",
    "    if type(l) is str:\n",
    "        if l == \"\":\n",
    "            return -1\n",
    "        else:\n",
    "            return outcomes_dict[l]\n",
    "    else:\n",
    "        return [l2i(l_) for l_ in l]\n",
    "#i can either be a list of indices, or just an index\n",
    "def i2l(i):\n",
    "    if type(i) is int:\n",
    "        return outcomes[i]\n",
    "    else:\n",
    "        return [outcomes[i_] for i_ in i]\n",
    "def e_prop(E, s):\n",
    "    result = list()\n",
    "    for i in range(len(s)):\n",
    "        if i < 0:\n",
    "            result.append(-1)\n",
    "        else:\n",
    "            result.append(E[i, s[i]])\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1852441 1852441\n"
     ]
    }
   ],
   "source": [
    "def read_fasta_file(filename):\n",
    "    \"\"\"\n",
    "    Reads the given FASTA file f and returns a dictionary of sequences.\n",
    "\n",
    "    Lines starting with ';' in the FASTA file are ignored.\n",
    "    \"\"\"\n",
    "    sequences_lines = {}\n",
    "    current_sequence_lines = None\n",
    "    with open(filename) as fp:\n",
    "        for line in fp:\n",
    "            line = line.strip()\n",
    "            if line.startswith(';') or not line:\n",
    "                continue\n",
    "            if line.startswith('>'):\n",
    "                sequence_name = line.lstrip('>')\n",
    "                current_sequence_lines = []\n",
    "                sequences_lines[sequence_name] = current_sequence_lines\n",
    "            else:\n",
    "                if current_sequence_lines is not None:\n",
    "                    current_sequence_lines.append(line)\n",
    "    sequences = {}\n",
    "    for name, lines in sequences_lines.items():\n",
    "        sequences[name] = ''.join(lines)\n",
    "    return sequences\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "genome = ''\n",
    "annotation = ''\n",
    "for i in range(1,2):\n",
    "    genome += read_fasta_file('data/genome%d.fa' % i)['genome%d' % i]\n",
    "    annotation += read_fasta_file('data/annotation%d.fa' % i)['annotation%d' % i]\n",
    "\n",
    "print(len(genome), len(annotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'AAA' 'AAC' 'AAG' 'AAT' 'ACA' 'ACC' 'ACG' 'ACT' 'AGA' 'AGC' 'AGG'\n",
      " 'AGT' 'ATA' 'ATC' 'ATG' 'ATT' 'C' 'CAA' 'CAC' 'CAG' 'CAT' 'CCA' 'CCC'\n",
      " 'CCG' 'CCT' 'CGA' 'CGC' 'CGG' 'CGT' 'CTA' 'CTC' 'CTG' 'CTT' 'G' 'GAA'\n",
      " 'GAC' 'GAG' 'GAT' 'GCA' 'GCC' 'GCG' 'GCT' 'GGA' 'GGC' 'GGG' 'GGT' 'GTA'\n",
      " 'GTC' 'GTG' 'GTT' 'T' 'TAA' 'TAC' 'TAG' 'TAT' 'TCA' 'TCC' 'TCG' 'TCT'\n",
      " 'TGA' 'TGC' 'TGG' 'TGT' 'TTA' 'TTC' 'TTG' 'TTT']\n",
      "{'GCG': 41, 'TCA': 56, 'AAG': 3, 'GAG': 37, 'TAG': 54, 'CAG': 20, 'TTT': 67, 'CTA': 30, 'ATA': 13, 'AAA': 1, 'CGT': 29, 'TTG': 66, 'ATT': 16, 'GCC': 40, 'CAC': 19, 'GCT': 42, 'ACC': 6, 'A': 0, 'GTG': 49, 'ATG': 15, 'TGG': 62, 'TCT': 59, 'CGG': 28, 'GAA': 35, 'CGA': 26, 'T': 51, 'CAA': 18, 'TGT': 63, 'GTT': 50, 'GTA': 47, 'ACA': 5, 'CTT': 33, 'TCC': 57, 'CGC': 27, 'TCG': 58, 'GGC': 44, 'AAT': 4, 'CAT': 21, 'CCG': 24, 'GGA': 43, 'AGA': 9, 'CCT': 25, 'ACG': 7, 'GTC': 48, 'CTG': 32, 'CCA': 22, 'GGG': 45, 'TAT': 55, 'GAC': 36, 'TTC': 65, 'GAT': 38, 'CCC': 23, 'ATC': 14, 'ACT': 8, 'TTA': 64, 'AGT': 12, 'GCA': 39, 'TAA': 52, 'TGA': 60, 'AGG': 11, 'TAC': 53, 'CTC': 31, 'TGC': 61, 'AAC': 2, 'GGT': 46, 'G': 34, 'AGC': 10, 'C': 17}\n",
      "['Noncoding' 'C-start' 'C-codon' 'C-stop' 'R-start' 'R-codon' 'R-stop']\n",
      "[1 3 3 3 3 3 3]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "npzfile = np.load('codon_hmm_from_counting.npz')\n",
    "A = npzfile['A']\n",
    "E = npzfile['E']\n",
    "pi = npzfile['pi']\n",
    "\n",
    "# define all possible outcomes of all states:\n",
    "outcomes_dict = {} # ohh gawd this is akward\n",
    "outcomes = np.empty([68], dtype=object) # help me, im lost\n",
    "i = 0\n",
    "letters = 'ACGT'\n",
    "for letter1 in letters:\n",
    "    outcomes[i] = letter1\n",
    "    outcomes_dict[letter1] = i\n",
    "    i += 1\n",
    "    for letter2 in letters:\n",
    "        for letter3 in letters:\n",
    "            outcomes[i] = letter1 + letter2 + letter3\n",
    "            outcomes_dict[letter1 + letter2 + letter3] = i\n",
    "            i += 1\n",
    "            \n",
    "            \n",
    "print(outcomes)\n",
    "print(outcomes_dict)\n",
    "\n",
    "\n",
    "state_codes=npzfile['state_codes']\n",
    "state_desc=npzfile['state_desc']\n",
    "\n",
    "q = 3*np.ones(len(state_desc), dtype=np.int32)\n",
    "q[0] = 1\n",
    "print(state_desc)\n",
    "print(q)\n",
    "\n",
    "def l2i(l):\n",
    "    if type(l) is str:\n",
    "        if l == \"\" or len(l) == 2:\n",
    "            return -1\n",
    "        else:\n",
    "            return outcomes_dict[l]\n",
    "    else:\n",
    "        return [l2i(l_) for l_ in l]\n",
    "#i can either be a list of indices, or just an index\n",
    "def i2l(i):\n",
    "    if type(i) is int:\n",
    "        return outcomes[i]\n",
    "    else:\n",
    "        return [outcomes[i_] for i_ in i]\n",
    "def e_prop(E, s):\n",
    "    result = list()\n",
    "    for i in range(len(s)):\n",
    "        result.append(E[i, s[i]])\n",
    "    return result\n",
    "\n",
    "print(type(outcomes))\n",
    "print(type(outcomes_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morten/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "/home/morten/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "/home/morten/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/home/morten/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "/home/morten/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:33: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620000[[-6.566 -13.136 -23.910 ..., -2638844.177 -2638850.747 -2638809.254]\n",
      " [-inf -inf -27.978 ..., -inf -inf -inf]\n",
      " [-inf -inf -inf ..., -2638791.067 -2638803.009 -inf]\n",
      " ..., \n",
      " [-inf -inf -inf ..., -inf -inf -inf]\n",
      " [-inf -inf -inf ..., -inf -inf -inf]\n",
      " [-inf -inf -inf ..., -inf -inf -inf]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morten/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:47: RuntimeWarning: divide by zero encountered in log\n",
      "/home/morten/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:48: RuntimeWarning: divide by zero encountered in log\n",
      "/home/morten/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:49: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 2 3 0]\n"
     ]
    }
   ],
   "source": [
    "#This is the Viterbi algorithm, where different states, can take input of different length.\n",
    "#A, E, p and s is as above. q is a vector, signifying the length of inputs for each state.\n",
    "\n",
    "s = genome\n",
    "\n",
    "def viterbi_ext_gen(A, E, p, s, q):\n",
    "    A = np.log(A)\n",
    "    E = (np.log(E).T*((17-5*q)//2)).T\n",
    "    p = np.log(p)\n",
    "    #We convert the input string to a numpy char-array\n",
    "    s_ = np.chararray(len(s), unicode=True)\n",
    "    s_[:] = list(s)\n",
    "    s = s_\n",
    "    #Then we generate some result matrix, with -1 everywhere.\n",
    "    result = np.log(np.zeros([A.shape[0], len(s)]))\n",
    "    #We save how long we have gotten in each \"row\"\n",
    "    step = np.zeros(A.shape[0], dtype=np.int32)\n",
    "    #We store the first row, to know the probability of starting in each state.\n",
    "    s_ = l2i(s[0:3])\n",
    "    result[:, 0] = (e_prop(E, s_)+p.T)\n",
    "    step = step+q\n",
    "    for i in range(1, len(s)):\n",
    "        if i % 10000 == 0:\n",
    "            print(\"\\r\" + str(i), end=\"\")\n",
    "        #First we calculate the argument of the ealier state max probability.\n",
    "        arg =  (A.T + result[:, i-1]).argmax(axis=1)\n",
    "        #Then we calculate the actual max\n",
    "        m = (A.T + result[:, i-1]).max(axis=1)\n",
    "        #Then we calculate the emission probability\n",
    "        step_ = step[arg]\n",
    "        s_ = [s[step_[i]:step_[i]+3] for i in range(len(step))]\n",
    "        s_ = l2i(s_)\n",
    "        e = np.log(np.zeros(len(s_)))\n",
    "        for j in range(len(s_)):\n",
    "            if (s_[j] != -1):\n",
    "                    e[j] = E[j, s_[j]]\n",
    "        #Then we fill in the actual probabilities\n",
    "        result[:, i] = m+e\n",
    "        step = step_ + q\n",
    "        highest = np.argmax(result[:, i])\n",
    "        if step[highest] >= len(s)-2:\n",
    "            result = result[:, :i+1]\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def viterbi_ext_path(X, A, E, p, s, q):\n",
    "    A = np.log(A)\n",
    "    E = np.log(E)\n",
    "    p = np.log(p)\n",
    "    n = X.shape[1]-1\n",
    "    j = len(s)\n",
    "    path = -1*np.ones(n+1, dtype=np.int32)\n",
    "    path[n] = np.argmax(X[:, n], axis=0)\n",
    "    for i in range(n, 0, -1):\n",
    "        q_ = q[path[i]]\n",
    "        s_ = s[j-q_:j]\n",
    "        p = E[path[i], l2i(s_)]\n",
    "        p = p + X[:, i-1]\n",
    "        p = p + A[:, path[i]]\n",
    "        path[i-1] = np.argmax(p)\n",
    "        j = j-q_\n",
    "    return path\n",
    "\n",
    "def viterbi_ext_annotation(genome, path):\n",
    "    annotation = np.empty(len(path), dtype=object)\n",
    "    annotation[path == 0] = 'N'\n",
    "    annotation[path == 1] = 'CCC'\n",
    "    annotation[path == 2] = 'CCC'\n",
    "    annotation[path == 3] = 'CCC'\n",
    "    annotation[path == 4] = 'RRR'\n",
    "    annotation[path == 5] = 'RRR'\n",
    "    annotation[path == 6] = 'RRR'\n",
    "    annotation = \"\".join(annotation)\n",
    "    while len(annotation) < len(genome):\n",
    "        annotation+=\"N\"\n",
    "\n",
    "X = viterbi_ext_gen(A, E, pi, s, q)\n",
    "print(X)\n",
    "path = viterbi_ext_path(X, A, E, pi, s, q)\n",
    "print(path)\n",
    "annotation = viterbi_ext_annotation(s, path)\n",
    "print(annotation)\n",
    "write_fasta_file('data/annotation_prediction_1.fa', annotation, 'data/genome1.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only Cs (tp=566698, fp=389519, tn=2837, fn=1154):\n",
      "Sn = 0.9980, Sp = 0.5926, CC = 0.0397, AC = 0.1543\n",
      "Only Rs (tp=484918, fp=407315, tn=2960, fn=1031):\n",
      "Sn = 0.9979, Sp = 0.5435, CC = 0.0381, AC = 0.1451\n",
      "Both (tp=1051616, fp=796834, tn=1806, fn=2185):\n",
      "Sn = 0.9979, Sp = 0.5689, CC = 0.0020, AC = 0.0108\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# compare_anns.py <true> <pred>\n",
    "#\n",
    "# compares a predicted gene structure against the true gene structure and computes\n",
    "# various statistics summarizing the quality of the prediction. The argument <true> is \n",
    "# the true gene structure in faste format, and <pred> is the predicted gene structure \n",
    "# in fasta format, e.g.\n",
    "#\n",
    "# > python compare_anns.py ./annotation1.fa ./pred1.fa\n",
    "# > Only Cs (tp=728238, fp=0, tn=505177, fn=249):\n",
    "# > Sn = 0.9997, Sp = 1.0000, CC = 0.9996, AC = 0.9996\n",
    "# > Only Rs (tp=618777, fp=0, tn=505426, fn=0):\n",
    "# > Sn = 1.0000, Sp = 1.0000, CC = 1.0000, AC = 1.0000\n",
    "# > Both (tp=1347015, fp=0, tn=505177, fn=249):\n",
    "# > Sn = 0.9998, Sp = 1.0000, CC = 0.9997, AC = 0.9997\n",
    "#\n",
    "# Christian Storm <cstorm@birc.au.dk>\n",
    "#\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import math\n",
    "\n",
    "def read_ann(filename):\n",
    "    lines = []\n",
    "    for l in open(filename).readlines():\n",
    "        if l[0] != \">\" and l[0] != ';':\n",
    "            lines.append(l.strip())\n",
    "    return \"\".join(lines)\n",
    "\n",
    "def count_c(true, pred):\n",
    "    total = tp = fp = tn = fn = 0\n",
    "    for i in range(len(true)):\n",
    "        if pred[i] == 'C' or pred[i] == 'c':\n",
    "            total = total + 1\n",
    "            if true[i] == 'C' or true[i] == 'c':\n",
    "                tp = tp + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "        if pred[i] == 'N' or pred[i] == 'n':\n",
    "            if true[i] == 'N' or true[i] == 'n' or true[i] == 'R' or true[i] == 'r':\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "    return(total, tp, fp, tn, fn)\n",
    "\n",
    "def count_r(true, pred):\n",
    "    total = tp = fp = tn = fn = 0\n",
    "    for i in range(len(true)):\n",
    "        if pred[i] == 'R' or pred[i] == 'r':\n",
    "            total = total + 1\n",
    "            if true[i] == 'R' or true[i] == 'r':\n",
    "                tp = tp + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "        if pred[i] == 'N' or pred[i] == 'n':\n",
    "            if true[i] == 'N' or true[i] == 'n' or true[i] == 'C' or true[i] == 'c':\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "    return(total, tp, fp, tn, fn)\n",
    "\n",
    "def count_cr(true, pred):\n",
    "    total = tp = fp = tn = fn = 0\n",
    "    for i in range(len(true)):\n",
    "        if pred[i] == 'C' or pred[i] == 'c' or pred[i] == 'R' or pred[i] == 'r':\n",
    "            total = total + 1\n",
    "            if (pred[i] == 'C' or pred[i] == 'c') and (true[i] == 'C' or true[i] == 'c'):\n",
    "                tp = tp + 1\n",
    "            elif (pred[i] == 'R' or pred[i] == 'r') and (true[i] == 'R' or true[i] == 'r'):\n",
    "                tp = tp + 1                \n",
    "            else:\n",
    "                fp = fp + 1\n",
    "        if pred[i] == 'N' or pred[i] == 'n':\n",
    "            if true[i] == 'N' or true[i] == 'n':\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "    return(total, tp, fp, tn, fn)\n",
    "\n",
    "def print_stats(tp, fp, tn, fn):\n",
    "    sn = float(tp) / (tp + fn)\n",
    "    sp = float(tp) / (tp + fp)\n",
    "    cc = float((tp*tn - fp*fn)) / math.sqrt(float((tp+fn)*(tn+fp)*(tp+fp)*(tn+fn)))\n",
    "    acp = 0.25 * (float(tp)/(tp+fn) + float(tp)/(tp+fp) + float(tn)/(tn+fp) + float(tn)/(tn+fn))\n",
    "    ac = (acp - 0.5) * 2\n",
    "    print(\"Sn = %.4f, Sp = %.4f, CC = %.4f, AC = %.4f\" % (sn, sp, cc, ac))\n",
    "\n",
    "def print_all(true, pred):\n",
    "    (totalc, tp, fp, tn, fn) = count_c(true, pred)\n",
    "    if totalc > 0:\n",
    "        print(\"Only Cs (tp=%d, fp=%d, tn=%d, fn=%d):\" % (tp, fp, tn, fn))\n",
    "        print_stats(tp, fp, tn, fn)\n",
    "\n",
    "    (totalr, tp, fp, tn, fn) = count_r(true, pred)\n",
    "    if totalr > 0:\n",
    "        print(\"Only Rs (tp=%d, fp=%d, tn=%d, fn=%d):\" % (tp, fp, tn, fn))\n",
    "        print_stats(tp, fp, tn, fn)\n",
    "\n",
    "    (total, tp, fp, tn, fn) = count_cr(true, pred)\n",
    "    if totalc > 0 and totalr > 0:\n",
    "        print(\"Both (tp=%d, fp=%d, tn=%d, fn=%d):\" % (tp, fp, tn, fn))\n",
    "        print_stats(tp, fp, tn, fn)\n",
    "\n",
    "\n",
    "# Read true annotation\n",
    "true_ann = read_ann('data/annotation1.fa')\n",
    "\n",
    "# Read predicted annotations\n",
    "pred_ann = read_ann('data/annotation_prediction_1.fa')\n",
    "# Check annoation length\n",
    "error = 0\n",
    "if len(true_ann) != len(pred_ann):\n",
    "    print(\"ERROR: The lengths of two predictions are different\")\n",
    "    print(\"Expected %d, but found %d\" % (len(true_ann), len(pred_ann)))\n",
    "    sys.exit(1)    \n",
    "    \n",
    "# Print stats\n",
    "print_all(true_ann, pred_ann)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
