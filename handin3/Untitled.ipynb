{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "# oh so pretty!\n",
    "def float_formatter(x):\n",
    "    if x < 0.001 and x > 0:\n",
    "        return \"   >0\" \n",
    "    elif x == 0:\n",
    "        return \"    0\" \n",
    "    else:\n",
    "        return \"%.3f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "def _logsum(logx, logy):\n",
    "    print(\"Test\")\n",
    "    print(logx)\n",
    "    print(logy)\n",
    "    if len(logx.shape) < 1:\n",
    "        if np.isinf(logx) or np.isinf(logy):\n",
    "            print(\"result\")\n",
    "            print(np.max([logx, logy]))\n",
    "            return np.max([logx, logy])\n",
    "        else:\n",
    "            print(\"result\")\n",
    "            print(np.logaddexp(logx, logy))\n",
    "            return np.logaddexp(logx, logy)\n",
    "    else:\n",
    "        b = np.any([np.isinf(logx), np.isinf(logy)], axis=1)\n",
    "        print(b)\n",
    "        result = np.zeros(shape=logx.shape[0])\n",
    "        result[b] = np.maximum(logx[b], logy[b])\n",
    "        result[not b] = np.logaddexp(logx[not b], logy[not b])\n",
    "        print(\"result\")\n",
    "        print(result)\n",
    "        return result\n",
    "\n",
    "def write_fasta_file(annotation_file_to_save, annotation_string, genome_file=None):\n",
    "    if (genome_file!=None):\n",
    "        with open(genome_file) as gf:\n",
    "            first_line = gf.readline()\n",
    "            s = \" \"\n",
    "            words = first_line.split(s)\n",
    "            words[0] = words[0] + \" gene annotation\"\n",
    "            first_line = s.join(words[:-1])\n",
    "    else:\n",
    "        first_line = \"; gene annotation\"\n",
    "    with open(annotation_file_to_save, 'w+') as af:\n",
    "        af.write(first_line + '\\n')\n",
    "        name = annotation_file_to_save.replace('/', '\\\\').split('\\\\')[-1].split('.fa')[0]\n",
    "        af.write('>' + name + '\\n')\n",
    "        line_length = 60\n",
    "        full_lines = len(annotation_string)//line_length\n",
    "        for anot_line in range(full_lines):\n",
    "            af.write(annotation_string[anot_line*line_length:(anot_line+1)*line_length] + '\\n')\n",
    "        af.write(annotation_string[(full_lines)*line_length:])\n",
    "       \n",
    "    \n",
    "# eg\n",
    "#write_fasta_file(\"data/annotation13.fa\", \"ABABABABABABABABABAAAAJHASJHASJJSdskfjklsfkjklj sdhjkøfhjkø ksdhjf jkjkhsdfjk hjksdf hjksdfjk jhksd fhjkdsfhjk AJJSJHASHJASJJHASJHASJHASJHSAJJHASJHASHJASJJHASJHASJJHASJH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_fasta_file(filename):\n",
    "    \"\"\"\n",
    "    Reads the given FASTA file f and returns a dictionary of sequences.\n",
    "\n",
    "    Lines starting with ';' in the FASTA file are ignored.\n",
    "    \"\"\"\n",
    "    sequences_lines = {}\n",
    "    current_sequence_lines = None\n",
    "    with open(filename) as fp:\n",
    "        for line in fp:\n",
    "            line = line.strip()\n",
    "            if line.startswith(';') or not line:\n",
    "                continue\n",
    "            if line.startswith('>'):\n",
    "                sequence_name = line.lstrip('>')\n",
    "                current_sequence_lines = []\n",
    "                sequences_lines[sequence_name] = current_sequence_lines\n",
    "            else:\n",
    "                if current_sequence_lines is not None:\n",
    "                    current_sequence_lines.append(line)\n",
    "    sequences = {}\n",
    "    for name, lines in sequences_lines.items():\n",
    "        sequences[name] = ''.join(lines)\n",
    "    return sequences\n",
    "\n",
    "def load_data(n):\n",
    "    train_genome = ''\n",
    "    train_annotation = ''\n",
    "    indices = [1, 2, 3, 4, 5]\n",
    "    test_genome = ''\n",
    "    test_annotation = ''\n",
    "    for i in indices:\n",
    "        if i != n:\n",
    "            train_genome += read_fasta_file('data/genome%d.fa' % i)['genome%d' % i]\n",
    "            train_annotation += read_fasta_file('data/annotation%d.fa' % i)['annotation%d' % i]\n",
    "        \n",
    "    test_genome += read_fasta_file('data/genome%d.fa' % n)['genome%d' % n]\n",
    "    #test_annotation += read_fasta_file('data/annotation%d.fa' % n)['annotation%d' % n]\n",
    "    return train_genome, train_annotation, test_genome, test_annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First we create our model:\n",
    "states = ['noncoding', 'c-start-codon', 'c-content-codon', 'c-end-codon', 'r-start-codon', 'r-content-codon', 'r-end-codon']\n",
    "    \n",
    "# define all possible outcomes of all states:\n",
    "outcomes_dict = {} # ohh gawd this is akward\n",
    "outcomes = np.empty([68], dtype=object) # help me, im lost\n",
    "i = 0\n",
    "letters = 'ACGT'\n",
    "for letter1 in letters:\n",
    "    outcomes[i] = letter1\n",
    "    outcomes_dict[letter1] = i\n",
    "    i += 1\n",
    "    for letter2 in letters:\n",
    "        for letter3 in letters:\n",
    "            outcomes[i] = letter1 + letter2 + letter3\n",
    "            outcomes_dict[letter1 + letter2 + letter3] = i\n",
    "            i += 1\n",
    "\n",
    "def build_model(train_genome, train_annotation):\n",
    "    #First we create our model:\n",
    "    states = ['noncoding', 'c-start-codon', 'c-content-codon', 'c-end-codon', 'r-start-codon', 'r-content-codon', 'r-end-codon']\n",
    "    \n",
    "    # define all possible outcomes of all states:\n",
    "    outcomes_dict = {} # ohh gawd this is akward\n",
    "    outcomes = np.empty([68], dtype=object) # help me, im lost\n",
    "    i = 0\n",
    "    letters = 'ACGT'\n",
    "    for letter1 in letters:\n",
    "        outcomes[i] = letter1\n",
    "        outcomes_dict[letter1] = i\n",
    "        i += 1\n",
    "        for letter2 in letters:\n",
    "            for letter3 in letters:\n",
    "                outcomes[i] = letter1 + letter2 + letter3\n",
    "                outcomes_dict[letter1 + letter2 + letter3] = i\n",
    "                i += 1\n",
    "    \n",
    "    A = np.zeros((len(states), len(states)))\n",
    "    E = np.zeros((len(states), outcomes.shape[0]))\n",
    "    pi = np.zeros((len(states)))\n",
    "    pi[0] = 1\n",
    "    #Now we have to fill out the data.\n",
    "    #First we take care of transitions\n",
    "    A[0, 1] = train_annotation.count('NC')#N -> C\n",
    "    A[3, 0] = train_annotation.count('CN')# C -> N\n",
    "    A[0, 4] = train_annotation.count('NR')#N -> R \n",
    "    A[6, 0] = train_annotation.count('RN')#R -> N\n",
    "    A[3, 4] = train_annotation.count('CR')#C -> R\n",
    "    A[6, 1] = train_annotation.count('RC') #R -> C\n",
    "    A[0, 0] = train_annotation.count('N') - (A[0,1] + A[0,4])\n",
    "    A[1, 2] = 1 # C-start -> C-content\n",
    "    A[4, 5] = 1 # R-stop -> R-content\n",
    "    A[2, 2] = train_annotation.count('CCC') - (A[0, 1] + A[3,0] + A[3,4] + A[6,1]) # c-content -> c-content\n",
    "    A[5, 5] = train_annotation.count('RRR') - (A[0, 4] + A[6,0] + A[6,1] + A[3,4]) # r-content -> r-content\n",
    "    A[2, 3] = A[3, 4] + A[3, 0]\n",
    "    A[5, 6] = A[6, 1] + A[6, 0]\n",
    "    A = A/A.sum(axis=1)[:, None]\n",
    "    #Now we need to find emissions.\n",
    "    for m in re.finditer('CCC', train_annotation):\n",
    "        index = m.start()\n",
    "        genome_string = outcomes_dict[train_genome[index:index+3]]\n",
    "        if train_annotation[index-1] == 'C':\n",
    "            if train_annotation[index+3] == 'C':\n",
    "                E[2, genome_string] += 1\n",
    "            else:\n",
    "                E[3, genome_string] += 1\n",
    "        else:\n",
    "            E[1, genome_string] += 1\n",
    "    for m in re.finditer('RRR', train_annotation):\n",
    "        index = m.start()\n",
    "        genome_string = outcomes_dict[train_genome[index:index+3]]\n",
    "        if train_annotation[index-1] == 'R':\n",
    "            if train_annotation[index+3] == 'R':\n",
    "                E[5, genome_string] += 1\n",
    "            else:\n",
    "                E[6, genome_string] += 1\n",
    "        else:\n",
    "            E[4, genome_string] += 1\n",
    "    \n",
    "    for m in re.finditer('N', train_annotation):\n",
    "        index = m.start()\n",
    "        E[0, outcomes_dict[train_genome[index]]] += 1\n",
    "    \n",
    "    E = E/E.sum(axis=1)[:, None]\n",
    "    return A, E, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def l2i(l):\n",
    "    if type(l) is str:\n",
    "        if l == \"\" or len(l) == 2:\n",
    "            return -1\n",
    "        else:\n",
    "            return outcomes_dict[l]\n",
    "    else:\n",
    "        return [l2i(l_) for l_ in l]\n",
    "#i can either be a list of indices, or just an index\n",
    "def i2l(i):\n",
    "    if type(i) is int:\n",
    "        return outcomes[i]\n",
    "    else:\n",
    "        return [outcomes[i_] for i_ in i]\n",
    "def e_prop(E, s):\n",
    "    result = list()\n",
    "    for i in range(len(s)):\n",
    "        result.append(E[i, s[i]])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is the Viterbi algorithm, where different states, can take input of different length.\n",
    "#A, E, p and s is as above. q is a vector, signifying the length of inputs for each state.\n",
    "\n",
    "\n",
    "def logaddexplist(v1, v2):\n",
    "    result = np.logaddexp(v1, v2) \n",
    "    b1 = np.isinf(v1)\n",
    "    b2 = np.isinf(v2)\n",
    "    result[b1] = v2[b1]\n",
    "    result[b2] = v1[b2]\n",
    "    return result\n",
    "\n",
    "\n",
    "def viterbi_ext_gen(A, E, p, s):\n",
    "    A = np.log(A)\n",
    "    E = np.log(E)\n",
    "    p = np.log(p)\n",
    "    #Then we generate some result matrix, with -inf everywhere.\n",
    "    result = np.log(np.zeros([A.shape[0], len(s)]))\n",
    "    \n",
    "    #First we make the base cases\n",
    "    obs = [s[i] for i in range(3)]\n",
    "    #first row only relies on the probabolity of starting in a state and the emission probability of the first observation.\n",
    "    result[:, 0] = p + E[:, l2i(obs[0])]\n",
    "    #second row relies on the probability of coming from the first state, and the emission probability of the second observation\n",
    "    result[:, 1] = (result[:, 0] + (A[:, :].T)).max(axis=1) + E[:, l2i(obs[1])]\n",
    "    \n",
    "    # The third row relies on the probability of starting in a state, and emission of the first three observations.\n",
    "    # After that it relies on the chance of coming from either an earlier state, and the last emission, or the first state,\n",
    "    # two emissions (not necesary in our case.)\n",
    "    result[:, 2] = np.maximum(p + E[:, l2i(obs[0] + obs[1] + obs[2])],\n",
    "                                (result[:, 1] + (A[:, :].T)).max(axis=1) + E[:, l2i(obs[2])])\n",
    "    \n",
    "    for i in range(3, len(s)):\n",
    "        obs = [s[i-j] for j in range(2, -1, -1)]\n",
    "        result[:, i] = np.maximum((result[:, i-3] + (A[:, :].T)).max(axis=1) + E[:, l2i(obs[0] + obs[1] + obs[2])],\n",
    "                                (result[:, i-1] + (A[:, :].T)).max(axis=1) + E[:, l2i(obs[2])])\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "def viterbi_ext_path(X, A, E, p, s):\n",
    "    A = np.log(A)\n",
    "    E = np.log(E)\n",
    "    p = np.log(p)\n",
    "    path = -1*np.ones(X.shape[1], dtype=np.int32)\n",
    "    n = X.shape[1]-1\n",
    "    path[n] = X[:, n].argmax()\n",
    "    n -= 1\n",
    "    while n >= 2:\n",
    "        obs = [s[n-1], s[n], s[n+1]]\n",
    "        temp = np.zeros((X.shape[0], 2))\n",
    "        temp[:, 0] = (X[:, n-2] + A[:, path[n+1]]) + E[path[n+1], l2i(obs[0] + obs[1] + obs[2])]\n",
    "        temp[:, 1] = (X[:, n] + A[:, path[n+1]]) + E[path[n+1], l2i(obs[2])]\n",
    "        state, step = np.unravel_index(temp.argmax(), temp.shape)\n",
    "        if step == 0:\n",
    "            path[n-2] = state\n",
    "            n -= 3\n",
    "        else:\n",
    "            path[n] = state\n",
    "            n -= 1\n",
    "    while n >= 0:\n",
    "        path[n] = 0\n",
    "        n -= 1\n",
    "    return path[path > -1]\n",
    "\n",
    "def viterbi_ext_annotation(genome, path):\n",
    "    result = np.empty(len(path), dtype=object)\n",
    "    result[path == 0] = 'N'\n",
    "    result[path == 1] = 'CCC'\n",
    "    result[path == 2] = 'CCC'\n",
    "    result[path == 3] = 'CCC'\n",
    "    result[path == 4] = 'RRR'\n",
    "    result[path == 5] = 'RRR'\n",
    "    result[path == 6] = 'RRR'\n",
    "    result = \"\".join(result)\n",
    "    return result\n",
    "#print(A)\n",
    "#X = viterbi_ext_gen(A, E, pi, s)\n",
    "#print(\"boom\")\n",
    "#print(X[:, -3:])\n",
    "\n",
    "#path = viterbi_ext_path(X, A, E, pi, s)\n",
    "#print(path)\n",
    "#print((path!=0).sum())\n",
    "#for i in range(path.shape[0]):\n",
    "#    if path[i] == 1:\n",
    "#        print(X[:, i-2:i+2])\n",
    "#        break\n",
    "#annotation_pred = viterbi_ext_annotation(s, path)\n",
    "#print(len(test_genome))\n",
    "#print(len(annotation_pred))\n",
    "#print(annotation_pred)\n",
    "#write_fasta_file('data/annotation_prediction_5.fa', annotation_pred, 'data/genome5.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 4]\n",
      " [1 3]]\n",
      "[1 3]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "S = np.arange(4).reshape(2,2)\n",
    "S = S.T\n",
    "S[0,1] = 4\n",
    "print(S)\n",
    "print(S[1, :])\n",
    "print(S.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# compare_anns.py <true> <pred>\n",
    "#\n",
    "# compares a predicted gene structure against the true gene structure and computes\n",
    "# various statistics summarizing the quality of the prediction. The argument <true> is \n",
    "# the true gene structure in faste format, and <pred> is the predicted gene structure \n",
    "# in fasta format, e.g.\n",
    "#\n",
    "# > python compare_anns.py ./annotation1.fa ./pred1.fa\n",
    "# > Only Cs (tp=728238, fp=0, tn=505177, fn=249):\n",
    "# > Sn = 0.9997, Sp = 1.0000, CC = 0.9996, AC = 0.9996\n",
    "# > Only Rs (tp=618777, fp=0, tn=505426, fn=0):\n",
    "# > Sn = 1.0000, Sp = 1.0000, CC = 1.0000, AC = 1.0000\n",
    "# > Both (tp=1347015, fp=0, tn=505177, fn=249):\n",
    "# > Sn = 0.9998, Sp = 1.0000, CC = 0.9997, AC = 0.9997\n",
    "#\n",
    "# Christian Storm <cstorm@birc.au.dk>\n",
    "#\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import math\n",
    "\n",
    "def read_ann(filename):\n",
    "    lines = []\n",
    "    for l in open(filename).readlines():\n",
    "        if l[0] != \">\" and l[0] != ';':\n",
    "            lines.append(l.strip())\n",
    "    return \"\".join(lines)\n",
    "\n",
    "def count_c(true, pred):\n",
    "    total = tp = fp = tn = fn = 0\n",
    "    for i in range(len(true)):\n",
    "        if pred[i] == 'C' or pred[i] == 'c':\n",
    "            total = total + 1\n",
    "            if true[i] == 'C' or true[i] == 'c':\n",
    "                tp = tp + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "        if pred[i] == 'N' or pred[i] == 'n':\n",
    "            if true[i] == 'N' or true[i] == 'n' or true[i] == 'R' or true[i] == 'r':\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "    return(total, tp, fp, tn, fn)\n",
    "\n",
    "def count_r(true, pred):\n",
    "    total = tp = fp = tn = fn = 0\n",
    "    for i in range(len(true)):\n",
    "        if pred[i] == 'R' or pred[i] == 'r':\n",
    "            total = total + 1\n",
    "            if true[i] == 'R' or true[i] == 'r':\n",
    "                tp = tp + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "        if pred[i] == 'N' or pred[i] == 'n':\n",
    "            if true[i] == 'N' or true[i] == 'n' or true[i] == 'C' or true[i] == 'c':\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "    return(total, tp, fp, tn, fn)\n",
    "\n",
    "def count_cr(true, pred):\n",
    "    total = tp = fp = tn = fn = 0\n",
    "    for i in range(len(true)):\n",
    "        if pred[i] == 'C' or pred[i] == 'c' or pred[i] == 'R' or pred[i] == 'r':\n",
    "            total = total + 1\n",
    "            if (pred[i] == 'C' or pred[i] == 'c') and (true[i] == 'C' or true[i] == 'c'):\n",
    "                tp = tp + 1\n",
    "            elif (pred[i] == 'R' or pred[i] == 'r') and (true[i] == 'R' or true[i] == 'r'):\n",
    "                tp = tp + 1                \n",
    "            else:\n",
    "                fp = fp + 1\n",
    "        if pred[i] == 'N' or pred[i] == 'n':\n",
    "            if true[i] == 'N' or true[i] == 'n':\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "    return(total, tp, fp, tn, fn)\n",
    "\n",
    "def print_stats(tp, fp, tn, fn):\n",
    "    sn = float(tp) / (tp + fn)\n",
    "    sp = float(tp) / (tp + fp)\n",
    "    cc = float((tp*tn - fp*fn)) / math.sqrt(float((tp+fn)*(tn+fp)*(tp+fp)*(tn+fn)))\n",
    "    acp = 0.25 * (float(tp)/(tp+fn) + float(tp)/(tp+fp) + float(tn)/(tn+fp) + float(tn)/(tn+fn))\n",
    "    ac = (acp - 0.5) * 2\n",
    "    print(\"Sn = %.4f, Sp = %.4f, CC = %.4f, AC = %.4f\" % (sn, sp, cc, ac))\n",
    "\n",
    "def print_all(true, pred):\n",
    "    (totalc, tp, fp, tn, fn) = count_c(true, pred)\n",
    "    if totalc > 0:\n",
    "        print(\"Only Cs (tp=%d, fp=%d, tn=%d, fn=%d):\" % (tp, fp, tn, fn))\n",
    "        print_stats(tp, fp, tn, fn)\n",
    "\n",
    "    (totalr, tp, fp, tn, fn) = count_r(true, pred)\n",
    "    if totalr > 0:\n",
    "        print(\"Only Rs (tp=%d, fp=%d, tn=%d, fn=%d):\" % (tp, fp, tn, fn))\n",
    "        print_stats(tp, fp, tn, fn)\n",
    "\n",
    "    (total, tp, fp, tn, fn) = count_cr(true, pred)\n",
    "    if totalc > 0 and totalr > 0:\n",
    "        print(\"Both (tp=%d, fp=%d, tn=%d, fn=%d):\" % (tp, fp, tn, fn))\n",
    "        print_stats(tp, fp, tn, fn)\n",
    "\n",
    "\n",
    "# Read true annotation\n",
    "#true_ann = read_ann('data/annotation5.fa')\n",
    "\n",
    "# Read predicted annotations\n",
    "#pred_ann = read_ann('data/annotation_prediction_5.fa')\n",
    "# Check annoation length\n",
    "#error = 0\n",
    "#if len(true_ann) != len(pred_ann):\n",
    "#    print(\"ERROR: The lengths of two predictions are different\")\n",
    "#    print(\"Expected %d, but found %d\" % (len(true_ann), len(pred_ann)))\n",
    "#    sys.exit(1)    \n",
    "    \n",
    "# Print stats\n",
    "#print_all(true_ann, pred_ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Morten\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Morten\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Morten\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:17: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c9d90a304512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_genome\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_annotation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_genome\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_annotation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_genome\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_annotation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mviterbi_ext_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_genome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mviterbi_ext_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_genome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpred_annotation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mviterbi_ext_annotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_genome\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-dbb5bf3db40c>\u001b[0m in \u001b[0;36mviterbi_ext_gen\u001b[0;34m(A, E, p, s)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[1;31m#First we make the base cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[1;31m#first row only relies on the probabolity of starting in a state and the emission probability of the first observation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2i\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-dbb5bf3db40c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[1;31m#First we make the base cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[1;31m#first row only relies on the probabolity of starting in a state and the emission probability of the first observation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2i\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "for h in [6, 7, 8, 9, 10]:\n",
    "    train_genome, train_annotation, test_genome, test_annotation = load_data(h)\n",
    "    A, E, pi = build_model(train_genome, train_annotation)\n",
    "    X = viterbi_ext_gen(A, E, pi, test_genome)\n",
    "    path = viterbi_ext_path(X, A, E, pi, test_genome)\n",
    "    pred_annotation = viterbi_ext_annotation(test_genome, path)\n",
    "    write_fasta_file('data/annotation_prediction_'+ str(h) + '.fa', pred_annotation, 'data/genome'+ str(h) + '.fa')\n",
    "    print_all(test_annotation, pred_annotation)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
